{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert given array as a sparse connected fcn\n",
    "\n",
    "- Input node cannot be connected to the others\n",
    "- But all output nodes should be connected to at least one hidden node or input node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphtorch import SparseMatrix, SparseModel\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection also represents its acitvation function\n",
    "- 0 : not connected\n",
    "- 1 : linear \n",
    "- 2 : ReLU\n",
    "- 3 : Sigmoid\n",
    "- and so on..\n",
    "\n",
    "**this index can be changed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 : Not connected\n",
    "# 1 : linear\n",
    "# 2 : ReLU\n",
    "# 3 : Sigmoid\n",
    "activations = [None, None, nn.ReLU(), nn.Sigmoid()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [Concatenate layer output with additional input data](https://discuss.pytorch.org/t/concatenate-layer-output-with-additional-input-data/20462)\n",
    "- [When should I use nn.ModuleList and when should I use nn.Sequential?](https://discuss.pytorch.org/t/when-should-i-use-nn-modulelist-and-when-should-i-use-nn-sequential/5463/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "![](img/example1_1.png)\n",
    "\n",
    "![](img/example1_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = np.array([[0,2,0,0,2,0,0,0,0,0],\n",
    "                [2,0,2,0,0,0,0,0,0,0],\n",
    "                [0,2,0,2,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,1,1,0,0,0],\n",
    "                [0,0,0,0,0,0,1,1,0,0],\n",
    "                [0,0,0,0,0,0,0,0,0,3],\n",
    "                [0,0,0,0,0,0,0,0,3,0]])  \n",
    "in_dim = 5   \n",
    "out_dim = 2  \n",
    "mat_wann1 = SparseMatrix(mat1, in_dim, out_dim)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 2, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first position represents row : FROM\n",
    "mat1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second position represents column : TO\n",
    "mat1[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0, 2],\n",
       "       [2, 0, 2, 0, 0],\n",
       "       [0, 2, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get destinations of input layer\n",
    "mat1[:mat_wann1.num_hidden_nodes, :in_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num of total hidden nodes\n",
    "mat_wann1.num_hidden_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of hidden layers and its node index\n",
    "mat_wann1.hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get total number of connections\n",
    "mat_wann1.connection_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_weight = 1 \n",
    "model = SparseModel(mat_wann1, activations, constant_weight)\n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],  \n",
    "                        [6,7,8,9,10],  \n",
    "                        [11,12,13,14,15]])      \n",
    "numpy_input = torch.from_numpy(numpy_input).float()  \n",
    "\n",
    "output, nodes = model(numpy_input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000],\n",
       "        [1.0000, 1.0000],\n",
       "        [1.0000, 1.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_0': tensor([[ 7.],\n",
       "         [17.],\n",
       "         [27.]], grad_fn=<AddBackward0>), 'hidden_1': tensor([[ 4.],\n",
       "         [14.],\n",
       "         [24.]], grad_fn=<AddBackward0>), 'hidden_2': tensor([[ 6.],\n",
       "         [16.],\n",
       "         [26.]], grad_fn=<AddBackward0>), 'hidden_3': tensor([[11.],\n",
       "         [31.],\n",
       "         [51.]], grad_fn=<AddBackward0>), 'hidden_4': tensor([[10.],\n",
       "         [30.],\n",
       "         [50.]], grad_fn=<AddBackward0>), 'output_0': tensor([[1.0000],\n",
       "         [1.0000],\n",
       "         [1.0000]], grad_fn=<SigmoidBackward>), 'output_1': tensor([[1.0000],\n",
       "         [1.0000],\n",
       "         [1.0000]], grad_fn=<SigmoidBackward>)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9999, 2.0000],\n",
       "        [2.0000, 2.0000],\n",
       "        [2.0000, 2.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model to double the current output\n",
    "numpy_output = output *2 \n",
    "numpy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9990]], requires_grad=True), Parameter containing:\n",
      "tensor([[1.]], requires_grad=True)]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7307dbc63085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters()) \n",
    "model.train()\n",
    "\n",
    "for epoch in range(10) : \n",
    "    print([x for x in model.parameters()])\n",
    "    optimizer.zero_grad()\n",
    "    output, nodes = model(numpy_input)  \n",
    "    loss = criterion(output, numpy_output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "![](img/example2_1.png)\n",
    "\n",
    "![](img/example2_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2 = np.array([[2,0,0,0,0,0],\n",
    "                [0,0,0,3,0,1]])\n",
    "in_dim = 5\n",
    "out_dim = 1\n",
    "mat_wann2 = SparseMatrix(mat2, in_dim, out_dim)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_weight = 1 \n",
    "model = SparseModel(mat_wann2, activations, constant_weight)\n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],  \n",
    "                        [6,7,8,9,10],  \n",
    "                        [11,12,13,14,15]]) \n",
    "\n",
    "numpy_input = torch.from_numpy(numpy_input).float()  \n",
    "output, nodes = model(numpy_input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9820],\n",
       "        [ 6.9999],\n",
       "        [12.0000]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_0': tensor([[ 1.],\n",
       "         [ 6.],\n",
       "         [11.]], grad_fn=<ReluBackward0>), 'output_0': tensor([[ 1.9820],\n",
       "         [ 6.9999],\n",
       "         [12.0000]], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3\n",
    "\n",
    "![](img/example3_1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat3 = np.array([[2,0,0,3,0],\n",
    "                [0,0,0,0,1]])    \n",
    "in_dim = 5  \n",
    "out_dim = 2    \n",
    "mat_wann3 = SparseMatrix(mat3, in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_weight = 1 \n",
    "model = SparseModel(mat_wann3, activations, constant_weight)\n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],  \n",
    "                        [6,7,8,9,10],  \n",
    "                        [11,12,13,14,15]]) \n",
    "\n",
    "numpy_input = torch.from_numpy(numpy_input).float()  \n",
    "output, nodes = model(numpy_input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9820,  5.0000],\n",
       "        [ 6.9999, 10.0000],\n",
       "        [12.0000, 15.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_0': tensor([[ 1.9820],\n",
       "         [ 6.9999],\n",
       "         [12.0000]], grad_fn=<AddBackward0>), 'output_1': tensor([[ 5.],\n",
       "         [10.],\n",
       "         [15.]], grad_fn=<MmBackward>)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4\n",
    "\n",
    "![](img/example4_1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat4 = np.array([[3,0,1,0,0],\n",
    "                [0,3,0,0,0],\n",
    "                [0,0,0,2,0],\n",
    "                [0,0,0,0,2],\n",
    "                [0,0,1,2,0],\n",
    "                [0,0,1,0,0]])\n",
    "in_dim = 3\n",
    "out_dim = 4\n",
    "mat_wann4 = SparseMatrix(mat4, in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_weight = 1 \n",
    "model = SparseModel(mat_wann4, activations, constant_weight)\n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],  \n",
    "                        [6,7,8,9,10],  \n",
    "                        [11,12,13,14,15]]) \n",
    "\n",
    "numpy_input = torch.from_numpy(numpy_input).float()  \n",
    "output, nodes = model(numpy_input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7311,  0.8808,  6.7311,  3.0000],\n",
       "        [ 8.9975,  0.9991, 16.9975,  8.0000],\n",
       "        [14.0000,  1.0000, 27.0000, 13.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_0': tensor([[ 3.7311],\n",
       "         [ 8.9975],\n",
       "         [14.0000]], grad_fn=<AddBackward0>), 'hidden_1': tensor([[0.8808],\n",
       "         [0.9991],\n",
       "         [1.0000]], grad_fn=<SigmoidBackward>), 'output_0': tensor([[ 3.7311],\n",
       "         [ 8.9975],\n",
       "         [14.0000]], grad_fn=<ReluBackward0>), 'output_1': tensor([[0.8808],\n",
       "         [0.9991],\n",
       "         [1.0000]], grad_fn=<ReluBackward0>), 'output_2': tensor([[ 6.7311],\n",
       "         [16.9975],\n",
       "         [27.0000]], grad_fn=<AddBackward0>), 'output_3': tensor([[ 3.],\n",
       "         [ 8.],\n",
       "         [13.]], grad_fn=<MmBackward>)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5\n",
    "\n",
    "![](img/example5_1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat5 = np.array([[0,2,0,0,2,0,0,0,0,0],\n",
    "                [2,0,2,0,0,0,0,0,0,0],\n",
    "                [0,2,0,2,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,1,1,0,0,0],\n",
    "                [0,0,0,2,0,0,1,1,0,0],\n",
    "                [0,0,0,0,0,0,0,0,0,3],\n",
    "                [0,0,0,0,0,0,0,0,3,0]])\n",
    "in_dim = 5\n",
    "out_dim = 2\n",
    "mat_wann5 = SparseMatrix(mat5, in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_weight = 1 \n",
    "model = SparseModel(mat_wann5, activations, constant_weight)\n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],  \n",
    "                        [6,7,8,9,10],  \n",
    "                        [11,12,13,14,15]]) \n",
    "\n",
    "numpy_input = torch.from_numpy(numpy_input).float()  \n",
    "output, nodes = model(numpy_input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000],\n",
       "        [1.0000, 1.0000],\n",
       "        [1.0000, 1.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_0': tensor([[ 7.],\n",
       "         [17.],\n",
       "         [27.]], grad_fn=<AddBackward0>), 'hidden_1': tensor([[ 4.],\n",
       "         [14.],\n",
       "         [24.]], grad_fn=<AddBackward0>), 'hidden_2': tensor([[ 6.],\n",
       "         [16.],\n",
       "         [26.]], grad_fn=<AddBackward0>), 'hidden_3': tensor([[11.],\n",
       "         [31.],\n",
       "         [51.]], grad_fn=<AddBackward0>), 'hidden_4': tensor([[14.],\n",
       "         [39.],\n",
       "         [64.]], grad_fn=<AddBackward0>), 'output_0': tensor([[1.0000],\n",
       "         [1.0000],\n",
       "         [1.0000]], grad_fn=<SigmoidBackward>), 'output_1': tensor([[1.0000],\n",
       "         [1.0000],\n",
       "         [1.0000]], grad_fn=<SigmoidBackward>)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
