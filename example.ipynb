{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphtorch import *\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = np.array([[0,2,0,0,2,0,0,0,0,0],\n",
    "                [2,0,2,0,0,0,0,0,0,0],\n",
    "                [0,2,0,2,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,1,1,0,0,0],\n",
    "                [0,0,0,0,0,0,1,1,0,0],\n",
    "                [0,0,0,0,0,0,0,0,0,3],\n",
    "                [0,0,0,0,0,0,0,0,3,0]])  \n",
    "in_dim = 5   \n",
    "out_dim = 2  \n",
    "mat_wann1 = MatrixForWANN(mat1, in_dim, out_dim)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2]\n",
      "connection from input :  [0 2 0 0 2 0 0 0 0 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 2\n",
      "\n",
      "**first input node\n",
      "tensor([[ 2.],\n",
      "        [ 7.],\n",
      "        [12.]], grad_fn=<ReluBackward0>)\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 2\n",
      "4 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 2.],\n",
      "        [ 7.],\n",
      "        [12.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 5.],\n",
      "        [10.],\n",
      "        [15.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[ 7.],\n",
      "        [17.],\n",
      "        [27.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 0\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 0\n",
      "connection from input :  [2 0 2 0 0 0 0 0 0 0]\n",
      "idx_input_col 0, activation_type 2\n",
      "\n",
      "**first input node\n",
      "tensor([[ 1.],\n",
      "        [ 6.],\n",
      "        [11.]], grad_fn=<ReluBackward0>)\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 2\n",
      "2 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 1.],\n",
      "        [ 6.],\n",
      "        [11.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 3.],\n",
      "        [ 8.],\n",
      "        [13.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[ 4.],\n",
      "        [14.],\n",
      "        [24.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 0\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 0\n",
      "connection from input :  [0 2 0 2 0 0 0 0 0 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 2\n",
      "\n",
      "**first input node\n",
      "tensor([[ 2.],\n",
      "        [ 7.],\n",
      "        [12.]], grad_fn=<ReluBackward0>)\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 2\n",
      "3 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 2.],\n",
      "        [ 7.],\n",
      "        [12.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 4.],\n",
      "        [ 9.],\n",
      "        [14.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[ 6.],\n",
      "        [16.],\n",
      "        [26.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 0\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 0\n",
      "connection from input :  [0 0 0 0 0 1 1 0 0 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 1\n",
      "\n",
      "**first input node\n",
      "tensor([[ 7.],\n",
      "        [17.],\n",
      "        [27.]], grad_fn=<MmBackward>)\n",
      "idx_input_col 6, activation_type 1\n",
      "6 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 7.],\n",
      "        [17.],\n",
      "        [27.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 4.],\n",
      "        [14.],\n",
      "        [24.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[11.],\n",
      "        [31.],\n",
      "        [51.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 0\n",
      "connection from input :  [0 0 0 0 0 0 1 1 0 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 1\n",
      "\n",
      "**first input node\n",
      "tensor([[ 4.],\n",
      "        [14.],\n",
      "        [24.]], grad_fn=<MmBackward>)\n",
      "idx_input_col 7, activation_type 1\n",
      "7 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 4.],\n",
      "        [14.],\n",
      "        [24.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 6.],\n",
      "        [16.],\n",
      "        [26.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[10.],\n",
      "        [30.],\n",
      "        [50.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 0\n",
      "connection from input :  [0 0 0 0 0 0 0 0 0 3]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 0\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 3\n",
      "\n",
      "**first input node\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "connection from input :  [0 0 0 0 0 0 0 0 3 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 0\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 3\n",
      "\n",
      "**first input node\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "idx_input_col 9, activation_type 0\n",
      "output 0\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "output 1\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "{'hidden_0': tensor([[ 7.],\n",
      "        [17.],\n",
      "        [27.]], grad_fn=<AddBackward0>), 'hidden_1': tensor([[ 4.],\n",
      "        [14.],\n",
      "        [24.]], grad_fn=<AddBackward0>), 'hidden_2': tensor([[ 6.],\n",
      "        [16.],\n",
      "        [26.]], grad_fn=<AddBackward0>), 'hidden_3': tensor([[11.],\n",
      "        [31.],\n",
      "        [51.]], grad_fn=<AddBackward0>), 'hidden_4': tensor([[10.],\n",
      "        [30.],\n",
      "        [50.]], grad_fn=<AddBackward0>), 'output_0': tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>), 'output_1': tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000],\n",
       "        [1.0000, 1.0000],\n",
       "        [1.0000, 1.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = [None, None, nn.ReLU(), nn.Sigmoid()]  \n",
    "constant_weight = 1 \n",
    "model = WANNFCN(mat_wann1, activations, constant_weight)\n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],  \n",
    "                        [6,7,8,9,10],  \n",
    "                        [11,12,13,14,15]])      \n",
    "\n",
    "numpy_input = torch.from_numpy(numpy_input).float()  \n",
    "model(numpy_input)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2 = np.array([[2,0,0,0,0,0],\n",
    "                [0,0,0,3,0,1]])\n",
    "in_dim = 5\n",
    "out_dim = 1\n",
    "mat_wann2 = sb.MatrixForWANN(mat2, in_dim, out_dim)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "connection from input :  [2 0 0 0 0 0]\n",
      "idx_input_col 0, activation_type 2\n",
      "\n",
      "**first input node\n",
      "tensor([[ 1.],\n",
      "        [ 6.],\n",
      "        [11.]], grad_fn=<ReluBackward0>)\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "connection from input :  [0 0 0 3 0 1]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 3\n",
      "\n",
      "**first input node\n",
      "tensor([[0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 1\n",
      "5 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[0.9820],\n",
      "        [0.9999],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 1.],\n",
      "        [ 6.],\n",
      "        [11.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[ 1.9820],\n",
      "        [ 6.9999],\n",
      "        [12.0000]], grad_fn=<AddBackward0>)\n",
      "output 0\n",
      "tensor([[ 1.9820],\n",
      "        [ 6.9999],\n",
      "        [12.0000]], grad_fn=<AddBackward0>)\n",
      "{'hidden_0': tensor([[ 1.],\n",
      "        [ 6.],\n",
      "        [11.]], grad_fn=<ReluBackward0>), 'output_0': tensor([[ 1.9820],\n",
      "        [ 6.9999],\n",
      "        [12.0000]], grad_fn=<AddBackward0>)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9820],\n",
       "        [ 6.9999],\n",
       "        [12.0000]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sb.WANNFCN(mat_wann2, sb.activations)  \n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],  \n",
    "                        [6,7,8,9,10],  \n",
    "                        [11,12,13,14,15]])      \n",
    "\n",
    "#numpy_input = np.array([[1,2,3,4,5]])  \n",
    "numpy_input = torch.from_numpy(numpy_input).float()  \n",
    "model(numpy_input)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat3 = np.array([[2,0,0,3,0],\n",
    "                [0,0,0,0,1]])    \n",
    "in_dim = 5  \n",
    "out_dim = 2    \n",
    "mat_wann3 = sb.MatrixForWANN(mat3, in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "output 0\n",
      "tensor([[ 1.9820],\n",
      "        [ 6.9999],\n",
      "        [12.0000]], grad_fn=<AddBackward0>)\n",
      "output 1\n",
      "tensor([[ 5.],\n",
      "        [10.],\n",
      "        [15.]], grad_fn=<MmBackward>)\n",
      "{'output_0': tensor([[ 1.9820],\n",
      "        [ 6.9999],\n",
      "        [12.0000]], grad_fn=<AddBackward0>), 'output_1': tensor([[ 5.],\n",
      "        [10.],\n",
      "        [15.]], grad_fn=<MmBackward>)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9820,  5.0000],\n",
       "        [ 6.9999, 10.0000],\n",
       "        [12.0000, 15.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sb.WANNFCN(mat_wann3, sb.activations)\n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],  \n",
    "                        [6,7,8,9,10],  \n",
    "                        [11,12,13,14,15]])      \n",
    "\n",
    "#numpy_input = np.array([[1,2,3,4,5]])  \n",
    "numpy_input = torch.from_numpy(numpy_input).float()  \n",
    "model(numpy_input)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 4__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat4 = np.array([[3,0,1,0,0],\n",
    "                [0,3,0,0,0],\n",
    "                [0,0,0,2,0],\n",
    "                [0,0,0,0,2],\n",
    "                [0,0,1,2,0],\n",
    "                [0,0,1,0,0]])\n",
    "in_dim = 3\n",
    "out_dim = 4\n",
    "mat_wann4 = sb.MatrixForWANN(mat4, in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "connection from input :  [3 0 1 0 0]\n",
      "idx_input_col 0, activation_type 3\n",
      "\n",
      "**first input node\n",
      "tensor([[0.7311],\n",
      "        [0.9975],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 1\n",
      "2 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[0.7311],\n",
      "        [0.9975],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 3.],\n",
      "        [ 8.],\n",
      "        [13.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[ 3.7311],\n",
      "        [ 8.9975],\n",
      "        [14.0000]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "connection from input :  [0 3 0 0 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 3\n",
      "\n",
      "**first input node\n",
      "tensor([[0.8808],\n",
      "        [0.9991],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "connection from input :  [0 0 0 2 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 2\n",
      "\n",
      "**first input node\n",
      "tensor([[ 3.7311],\n",
      "        [ 8.9975],\n",
      "        [14.0000]], grad_fn=<ReluBackward0>)\n",
      "idx_input_col 4, activation_type 0\n",
      "connection from input :  [0 0 0 0 2]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 2\n",
      "\n",
      "**first input node\n",
      "tensor([[0.8808],\n",
      "        [0.9991],\n",
      "        [1.0000]], grad_fn=<ReluBackward0>)\n",
      "connection from input :  [0 0 1 2 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 1\n",
      "\n",
      "**first input node\n",
      "tensor([[ 3.],\n",
      "        [ 8.],\n",
      "        [13.]], grad_fn=<MmBackward>)\n",
      "idx_input_col 3, activation_type 2\n",
      "3 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 3.],\n",
      "        [ 8.],\n",
      "        [13.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 3.7311],\n",
      "        [ 8.9975],\n",
      "        [14.0000]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[ 6.7311],\n",
      "        [16.9975],\n",
      "        [27.0000]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 4, activation_type 0\n",
      "connection from input :  [0 0 1 0 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 1\n",
      "\n",
      "**first input node\n",
      "tensor([[ 3.],\n",
      "        [ 8.],\n",
      "        [13.]], grad_fn=<MmBackward>)\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "output 0\n",
      "tensor([[ 3.7311],\n",
      "        [ 8.9975],\n",
      "        [14.0000]], grad_fn=<ReluBackward0>)\n",
      "output 1\n",
      "tensor([[0.8808],\n",
      "        [0.9991],\n",
      "        [1.0000]], grad_fn=<ReluBackward0>)\n",
      "output 2\n",
      "tensor([[ 6.7311],\n",
      "        [16.9975],\n",
      "        [27.0000]], grad_fn=<AddBackward0>)\n",
      "output 3\n",
      "tensor([[ 3.],\n",
      "        [ 8.],\n",
      "        [13.]], grad_fn=<MmBackward>)\n",
      "{'hidden_0': tensor([[ 3.7311],\n",
      "        [ 8.9975],\n",
      "        [14.0000]], grad_fn=<AddBackward0>), 'hidden_1': tensor([[0.8808],\n",
      "        [0.9991],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>), 'output_0': tensor([[ 3.7311],\n",
      "        [ 8.9975],\n",
      "        [14.0000]], grad_fn=<ReluBackward0>), 'output_1': tensor([[0.8808],\n",
      "        [0.9991],\n",
      "        [1.0000]], grad_fn=<ReluBackward0>), 'output_2': tensor([[ 6.7311],\n",
      "        [16.9975],\n",
      "        [27.0000]], grad_fn=<AddBackward0>), 'output_3': tensor([[ 3.],\n",
      "        [ 8.],\n",
      "        [13.]], grad_fn=<MmBackward>)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7311,  0.8808,  6.7311,  3.0000],\n",
       "        [ 8.9975,  0.9991, 16.9975,  8.0000],\n",
       "        [14.0000,  1.0000, 27.0000, 13.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sb.WANNFCN(mat_wann4, sb.activations)\n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],  \n",
    "                        [6,7,8,9,10],  \n",
    "                        [11,12,13,14,15]])      \n",
    "\n",
    "#numpy_input = np.array([[1,2,3,4,5]])  \n",
    "numpy_input = torch.from_numpy(numpy_input).float()  \n",
    "model(numpy_input)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 5__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat5 = np.array([[0,2,0,0,2,0,0,0,0,0],\n",
    "                [2,0,2,0,0,0,0,0,0,0],\n",
    "                [0,2,0,2,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,1,1,0,0,0],\n",
    "                [0,0,0,2,0,0,1,1,0,0],\n",
    "                [0,0,0,0,0,0,0,0,0,3],\n",
    "                [0,0,0,0,0,0,0,0,3,0]])\n",
    "in_dim = 5\n",
    "out_dim = 2\n",
    "mat_wann5 = sb.MatrixForWANN(mat5, in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2]\n",
      "connection from input :  [0 2 0 0 2 0 0 0 0 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 2\n",
      "\n",
      "**first input node\n",
      "tensor([[ 2.],\n",
      "        [ 7.],\n",
      "        [12.]], grad_fn=<ReluBackward0>)\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 2\n",
      "4 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 2.],\n",
      "        [ 7.],\n",
      "        [12.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 5.],\n",
      "        [10.],\n",
      "        [15.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[ 7.],\n",
      "        [17.],\n",
      "        [27.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 0\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 0\n",
      "connection from input :  [2 0 2 0 0 0 0 0 0 0]\n",
      "idx_input_col 0, activation_type 2\n",
      "\n",
      "**first input node\n",
      "tensor([[ 1.],\n",
      "        [ 6.],\n",
      "        [11.]], grad_fn=<ReluBackward0>)\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 2\n",
      "2 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 1.],\n",
      "        [ 6.],\n",
      "        [11.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 3.],\n",
      "        [ 8.],\n",
      "        [13.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[ 4.],\n",
      "        [14.],\n",
      "        [24.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 0\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 0\n",
      "connection from input :  [0 2 0 2 0 0 0 0 0 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 2\n",
      "\n",
      "**first input node\n",
      "tensor([[ 2.],\n",
      "        [ 7.],\n",
      "        [12.]], grad_fn=<ReluBackward0>)\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 2\n",
      "3 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 2.],\n",
      "        [ 7.],\n",
      "        [12.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 4.],\n",
      "        [ 9.],\n",
      "        [14.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[ 6.],\n",
      "        [16.],\n",
      "        [26.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 0\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 0\n",
      "connection from input :  [0 0 0 0 0 1 1 0 0 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 1\n",
      "\n",
      "**first input node\n",
      "tensor([[ 7.],\n",
      "        [17.],\n",
      "        [27.]], grad_fn=<MmBackward>)\n",
      "idx_input_col 6, activation_type 1\n",
      "6 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 7.],\n",
      "        [17.],\n",
      "        [27.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 4.],\n",
      "        [14.],\n",
      "        [24.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[11.],\n",
      "        [31.],\n",
      "        [51.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 0\n",
      "connection from input :  [0 0 0 2 0 0 1 1 0 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 2\n",
      "\n",
      "**first input node\n",
      "tensor([[ 4.],\n",
      "        [ 9.],\n",
      "        [14.]], grad_fn=<ReluBackward0>)\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 1\n",
      "6 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 4.],\n",
      "        [ 9.],\n",
      "        [14.]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 4.],\n",
      "        [14.],\n",
      "        [24.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[ 8.],\n",
      "        [23.],\n",
      "        [38.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 7, activation_type 1\n",
      "7 input node\n",
      "\n",
      "**input_node torch.Size([3, 1])\n",
      "tensor([[ 8.],\n",
      "        [23.],\n",
      "        [38.]], grad_fn=<AddBackward0>)\n",
      "\n",
      "**wrap_activation torch.Size([3, 1])\n",
      "tensor([[ 6.],\n",
      "        [16.],\n",
      "        [26.]], grad_fn=<MmBackward>)\n",
      "\n",
      "**sum torch.Size([3, 1])\n",
      "tensor([[14.],\n",
      "        [39.],\n",
      "        [64.]], grad_fn=<AddBackward0>)\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 0\n",
      "connection from input :  [0 0 0 0 0 0 0 0 0 3]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 0\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 0\n",
      "idx_input_col 9, activation_type 3\n",
      "\n",
      "**first input node\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "connection from input :  [0 0 0 0 0 0 0 0 3 0]\n",
      "idx_input_col 0, activation_type 0\n",
      "idx_input_col 1, activation_type 0\n",
      "idx_input_col 2, activation_type 0\n",
      "idx_input_col 3, activation_type 0\n",
      "idx_input_col 4, activation_type 0\n",
      "idx_input_col 5, activation_type 0\n",
      "idx_input_col 6, activation_type 0\n",
      "idx_input_col 7, activation_type 0\n",
      "idx_input_col 8, activation_type 3\n",
      "\n",
      "**first input node\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "idx_input_col 9, activation_type 0\n",
      "output 0\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "output 1\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)\n",
      "{'hidden_0': tensor([[ 7.],\n",
      "        [17.],\n",
      "        [27.]], grad_fn=<AddBackward0>), 'hidden_1': tensor([[ 4.],\n",
      "        [14.],\n",
      "        [24.]], grad_fn=<AddBackward0>), 'hidden_2': tensor([[ 6.],\n",
      "        [16.],\n",
      "        [26.]], grad_fn=<AddBackward0>), 'hidden_3': tensor([[11.],\n",
      "        [31.],\n",
      "        [51.]], grad_fn=<AddBackward0>), 'hidden_4': tensor([[14.],\n",
      "        [39.],\n",
      "        [64.]], grad_fn=<AddBackward0>), 'output_0': tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>), 'output_1': tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward>)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000],\n",
       "        [1.0000, 1.0000],\n",
       "        [1.0000, 1.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sb.WANNFCN(mat_wann5, sb.activations)\n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],  \n",
    "                        [6,7,8,9,10],  \n",
    "                        [11,12,13,14,15]])      \n",
    "\n",
    "#numpy_input = np.array([[1,2,3,4,5]])  \n",
    "numpy_input = torch.from_numpy(numpy_input).float()  \n",
    "model(numpy_input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
