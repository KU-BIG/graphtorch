{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphtorch import SparseMatrix, SparseModel\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import random\n",
    "import graphtorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 2__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2 = np.array([[2,0,0,0,0,0],\n",
    "                [0,0,0,3,0,1]])\n",
    "in_dim = 5\n",
    "out_dim = 1\n",
    "mat_wann2 = SparseMatrix(mat2, in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_wann2.connection_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_wann2.hidden_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 1__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = np.array([[0,2,0,0,2,0,0,0,0,0],\n",
    "                [2,0,2,0,0,0,0,0,0,0],\n",
    "                [0,2,0,2,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,1,1,0,0,0],\n",
    "                [0,0,0,0,0,0,1,1,0,0],\n",
    "                [0,0,0,0,0,0,0,0,0,3],\n",
    "                [0,0,0,0,0,0,0,0,3,0]])  \n",
    "in_dim = 5   \n",
    "out_dim = 2  \n",
    "mat_wann1 = SparseMatrix(mat1, in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "[3, 2]\n"
     ]
    }
   ],
   "source": [
    "print(mat_wann1.connection_count)\n",
    "print(mat_wann1.hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__three methods to change architecture__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_activation(SparseMatrix, activations):\n",
    "    \n",
    "    in_dim = SparseMatrix.in_dim\n",
    "    out_dim = SparseMatrix.out_dim\n",
    "    mat = SparseMatrix.mat  \n",
    "    indices = (mat != 0) #0이 아닌 index들만 activation 바꿀 수 있으니까 true false matrix 받기   \n",
    "    possible = [] # activation을 바꿀 수 있는 index 리스트. [[0, 0], [1, 3], [1, 5]] 이런 식으로 나옴 \n",
    "    \n",
    "    for i in range(indices.shape[0]):\n",
    "        for j in range(indices.shape[1]):\n",
    "            if indices[i,j] == True:\n",
    "                possible += [[i,j]]\n",
    "    \n",
    "    ran_idx = random.choice(possible) # [1,5] 이런 식으로 나오는데     \n",
    "    \n",
    "    #activations = [1, 2, 3] #linear, relu, sigmoid   \n",
    "    ran_activation = random.choice(activations)\n",
    "    \n",
    "    #change activation\n",
    "    mat[ran_idx[0],ran_idx[1]] = ran_activation \n",
    "    \n",
    "    new_SparseMatrix = graphtorch.SparseMatrix(mat, in_dim, out_dim) #이렇게 해야 callable 하더라고.. \n",
    "    \n",
    "\n",
    "    return new_SparseMatrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_connection(SparseMatrix):\n",
    "    \n",
    "    mat = SparseMatrix.mat \n",
    "    in_dim = SparseMatrix.in_dim\n",
    "    out_dim = SparseMatrix.out_dim  \n",
    "    hidden_dim = SparseMatrix.hidden_dim \n",
    "    \n",
    "    #random 하게 connection 추가 \n",
    "    # 같은 layer끼리는 connection x -> hidden layer끼리만 봐주면 됨 (input끼리 output끼리는 matrix에 없으니까) \n",
    "    # 0인 element 중에서 임의로 하나 바꾸기 -> 1,2,3 중에서(linear, relu, sigmoid)   \n",
    "    # 가능한 element 중에서 랜덤하게 하나의 element 뽑고, 거기서 또 (1,2,3) 중에서 랜덤하게 하나 뽑기  \n",
    "    \n",
    "    ###################\n",
    "    #hidden layer끼리 연결되어 있는 indices 들 뽑아내기\n",
    "    hidden_wise_indices = []\n",
    "    #print(hidden_dim[0])\n",
    "    row_start = 0\n",
    "    row_end = 0 + hidden_dim[0] - 1\n",
    "    col_start = in_dim \n",
    "    col_end = in_dim + hidden_dim[0] - 1 \n",
    "    #print(col_start, col_end)\n",
    "    \n",
    "    for hidden_count, current_hidden_dim in enumerate(hidden_dim): \n",
    "        #이전 laye의 dimension\n",
    "        for i in range(row_start, row_end + 1):\n",
    "            #print(col_start, col_end)\n",
    "            for j in range(col_start, col_end + 1):\n",
    "                \n",
    "                hidden_wise_indices += [[i,j]]\n",
    "        \n",
    "        row_start += current_hidden_dim  \n",
    "        col_start += current_hidden_dim \n",
    "        row_end += (current_hidden_dim - 1)  \n",
    "        col_end += (current_hidden_dim - 1)\n",
    "\n",
    "    ##################################    \n",
    "    #우선 0인 element들의 indices 받아오기   \n",
    "    indices = (mat == 0)     \n",
    "    zero_indices = [] # 0이 아닌 애들 indexes 우선 받아오기 \n",
    "    for i in range(indices.shape[0]):\n",
    "        for j in range(indices.shape[1]):\n",
    "            if indices[i,j] == True:\n",
    "                zero_indices += [[i,j]]\n",
    "    \n",
    "    \n",
    "    #################################\n",
    "    # hidden_wise_indices에 해당되지 않는 zero_indices만이 possible에 포함될 수 있음  \n",
    "    # (zero_indices) and (! hidden_wise_indices)\n",
    "    # 같은 hidden layer끼리 있지 않은 인덱스들 \n",
    "    possible = []\n",
    "    possible = [value for value in zero_indices if value not in hidden_wise_indices]  \n",
    "    \n",
    "    \n",
    "    # 우선 랜덤하게 어떤 element 바꿀 지 선택\n",
    "    ran_idx = random.choice(possible)\n",
    "    # select random activation -> 안하고 바로 liear 로 세팅\n",
    "    #possible_activation = [1, 2, 3] #linear, relu, sigmoid   \n",
    "    #ran_activation = random.choice(possible_activation)\n",
    "    \n",
    "    mat[ran_idx[0], ran_idx[1]] = 1   \n",
    "    \n",
    "    new_SparseMatrix = graphtorch.SparseMatrix(mat, in_dim, out_dim)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    return new_SparseMatrix\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node(SparseMatrix, activations):\n",
    "    \n",
    "    mat = SparseMatrix.mat \n",
    "    in_dim = SparseMatrix.in_dim\n",
    "    out_dim = SparseMatrix.out_dim  \n",
    "    hidden_dim = SparseMatrix.hidden_dim \n",
    "    \n",
    "    #이미 connection이 존재하는 부분 사이에 node 추가하기 \n",
    "    #원래 connection에 존재하던 activation 앞으로 넘길지 뒤로 넘길지 정하고, 나머지에는 랜덤하게 정해주기\n",
    "    #노드 추가해주면 dimension 추가해주고 connection 다시 계산해 줘야 하는데.. \n",
    "    \n",
    "    # connection이 존재하는 indices추출 \n",
    "    indices = (mat != 0)\n",
    "    possible = [] #node를 add할 수 있는 connection들 index 리스트 \n",
    "    for i in range(indices.shape[0]):\n",
    "        for j in range(indices.shape[1]):\n",
    "            if indices[i,j] == True:\n",
    "                possible += [[i,j]]    \n",
    "    #가능한 인덱스 중에서 하나 선택 \n",
    "    ran_idx = random.choice(possible) #[i,j] 형태로 나옴 \n",
    "    #랜덤하게 정할 activation 뽑기  \n",
    "    #possible_activation = [1,2,3]\n",
    "    ran_activation = random.choice(activations) \n",
    "    #원래 connection에 존재하던 activation type 앞으로 할지 뒤로 할지\n",
    "    front = 0 \n",
    "    back = 1\n",
    "    front_or_back = random.choice([front, back]) \n",
    "    #선택된 index의 원래 actavation 가지고있기\n",
    "    original_activation = mat[ran_idx[0], ran_idx[1]] \n",
    "    #선택된 index의 element 값 0으로 만들어주기\n",
    "    mat[ran_idx[0], ran_idx[1]] = 0\n",
    "    \n",
    "    \n",
    "    ## 몇번째 layer에 해당하는지만   \n",
    "    #그 layer 마지막에 추가해주기   \n",
    "    total_dim = [in_dim]\n",
    "    for i in range(len(hidden_dim)):\n",
    "        total_dim += [hidden_dim[i]]\n",
    "    total_dim += [out_dim]  \n",
    "    \n",
    "    \n",
    "    \n",
    "    #선택된 index 사이에 추가할 노드가 몇번째 hidden layer의 몇번째 hidden node인지 알아내야 -> mat의 index로 나오도록 \n",
    "    # 1) from이 input이고 to가 output인 경우\n",
    "        #\n",
    "    \n",
    "    # 2) from이 input이고 to가 첫번째 hidden 인 경우\n",
    "        # 삽입되는 노드가 to에 해당하는 hidden node 바로 \n",
    "    # 3) from이 hidden이고 to가 output인 경우\n",
    "    # 4) from이 hidden이고 to가 hidden인 경우 \n",
    "    \n",
    "    \n",
    "    \n",
    "    #matrix dimension 늘리기(앞의 index 활용해서 늘려야함)  \n",
    "    \n",
    "    \n",
    "    #element 값 할당하기 \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__print 디버깅__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 0 0 2 0 0 0 0 0]\n",
      " [2 0 2 0 0 0 0 0 0 0]\n",
      " [0 2 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 1 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 0 3 0]]\n"
     ]
    }
   ],
   "source": [
    "new = add_connection(mat_wann1)   \n",
    "print(new.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [0, 2], [0, 3], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [1, 1], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [2, 0], [2, 2], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [3, 7], [3, 8], [3, 9], [4, 0], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 8], [4, 9], [5, 0], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [6, 0], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 9]]\n"
     ]
    }
   ],
   "source": [
    "indices = (mat_wann1.mat == 0)\n",
    "possible = []\n",
    "for i in range(indices.shape[0]):\n",
    "    for j in range(indices.shape[1]):\n",
    "        if indices[i,j] == True:\n",
    "            possible += [[i,j]]\n",
    "\n",
    "            \n",
    "print(possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_activation = [1,2,3]\n",
    "random.choice(possible_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0 0]\n",
      " [0 0 0 2 0 1]]\n",
      "<class 'graphtorch.SparseMatrix'>\n"
     ]
    }
   ],
   "source": [
    "sparsemat = change_activation(mat_wann2)\n",
    "print(sparsemat.mat)\n",
    "print(type(sparsemat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curent_hidden_dim: 3\n",
      "row_start: 0\n",
      "row_end: 2\n",
      "col_start: 5\n",
      "col_end: 7\n",
      "curent_hidden_dim: 2\n",
      "row_start: 3\n",
      "row_end: 4\n",
      "col_start: 8\n",
      "col_end: 9\n"
     ]
    }
   ],
   "source": [
    "hidden_wise_indices = []\n",
    "row_start = 0\n",
    "row_end = 0 + mat_wann1.hidden_dim[0] - 1\n",
    "col_start = in_dim \n",
    "col_end = in_dim + mat_wann1.hidden_dim[0] - 1 \n",
    "    \n",
    "for hidden_count, current_hidden_dim in enumerate(mat_wann1.hidden_dim): \n",
    "    \n",
    "    #이전 laye의 dimension\n",
    "    \n",
    "    print(\"curent_hidden_dim: {}\".format(current_hidden_dim))\n",
    "    \n",
    "    print(\"row_start: {}\".format(row_start))\n",
    "    print(\"row_end: {}\".format(row_end))\n",
    "    print(\"col_start: {}\".format(col_start))\n",
    "    print(\"col_end: {}\".format(col_end))\n",
    "    for i in range(row_start, row_end + 1):\n",
    "        for j in range(col_start, col_end + 1):\n",
    "            hidden_wise_indices += [[i,j]]\n",
    "    \n",
    "    row_start += current_hidden_dim  \n",
    "    col_start += current_hidden_dim \n",
    "    row_end += (current_hidden_dim - 1)  \n",
    "    col_end += (current_hidden_dim - 1) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 5], [0, 6], [0, 7], [1, 5], [1, 6], [1, 7], [2, 5], [2, 6], [2, 7], [3, 8], [3, 9], [4, 8], [4, 9]]\n"
     ]
    }
   ],
   "source": [
    "print(hidden_wise_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [0, 2], [0, 3], [0, 8], [0, 9], [1, 1], [1, 3], [1, 4], [1, 8], [1, 9], [2, 0], [2, 2], [2, 4], [2, 8], [2, 9], [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [3, 7], [4, 0], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [5, 0], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [6, 0], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 9]]\n"
     ]
    }
   ],
   "source": [
    "lists = [value for value in possible if value not in hidden_wise_indices ]\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0 0]\n",
      " [0 0 0 3 0 1]]\n",
      "(2, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### test add dimension\n",
    "print(mat2)\n",
    "print(mat2.shape)\n",
    "idx = [1,3] \n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 3, 0, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 3 0 1]]\n"
     ]
    }
   ],
   "source": [
    "tmp = np.insert(mat2, 1, 0, axis = 0) #index, value to fill, axis \n",
    "print(tmp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "tmp = np.insert(tmp, 6, 0, axis = 1)\n",
    "print(tmp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
