{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphtorch import SparseMatrix, SparseModel\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import random\n",
    "import graphtorch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Change Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_activation(SparseMatrix, activations):\n",
    "    \n",
    "    in_dim = SparseMatrix.in_dim\n",
    "    out_dim = SparseMatrix.out_dim\n",
    "    mat = SparseMatrix.mat  \n",
    "    indices = (mat != 0) #0이 아닌 index들만 activation 바꿀 수 있으니까 true false matrix 받기   \n",
    "    possible = [] # activation을 바꿀 수 있는 index 리스트. [[0, 0], [1, 3], [1, 5]] 이런 식으로 나옴 \n",
    "    \n",
    "    for i in range(indices.shape[0]):   \n",
    "        for j in range(indices.shape[1]):   \n",
    "            if indices[i,j] == True:  \n",
    "                possible += [[i,j]]   \n",
    "    \n",
    "    ran_idx = random.choice(possible) # [1,5] 이런 식으로 나오는데     \n",
    "    \n",
    "    possible_activation = [i for i in range(len(activations))]\n",
    "    ran_activation = random.choice(possible_activation[1:])\n",
    "    \n",
    "    #change activation\n",
    "    mat[ran_idx[0],ran_idx[1]] = ran_activation \n",
    "    \n",
    "    new_SparseMatrix = graphtorch.SparseMatrix(mat, in_dim, out_dim) #이렇게 해야 callable 하더라고.. \n",
    "    \n",
    "\n",
    "    return new_SparseMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_connection(SparseMatrix):\n",
    "    \n",
    "    mat = SparseMatrix.mat \n",
    "    in_dim = SparseMatrix.in_dim\n",
    "    out_dim = SparseMatrix.out_dim  \n",
    "    hidden_dim = SparseMatrix.hidden_dim \n",
    "    \n",
    "    #random 하게 connection 추가 \n",
    "    # 같은 layer끼리는 connection x -> hidden layer끼리만 봐주면 됨 (input끼리 output끼리는 matrix에 없으니까) \n",
    "    # 0인 element 중에서 임의로 하나 바꾸기 -> 1,2,3 중에서(linear, relu, sigmoid)   \n",
    "    # 가능한 element 중에서 랜덤하게 하나의 element 뽑고, 거기서 또 (1,2,3) 중에서 랜덤하게 하나 뽑기  \n",
    "    \n",
    "    ###################\n",
    "    '''\n",
    "    #hidden dim이 0이 아닌 경우에만 (hidden_layer가 있는 경우에만)\n",
    "    #hidden layer끼리 연결되어 있는 indices 들 뽑아내기\n",
    "    if sum(hidden_dim) != 0:\n",
    "        hidden_wise_indices = [] \n",
    "\n",
    "        row_start = 0\n",
    "        row_end = 0 + hidden_dim[0] - 1\n",
    "        col_start = in_dim \n",
    "        col_end = in_dim + hidden_dim[0] - 1 \n",
    "        #print(col_start, col_end)\n",
    "\n",
    "        for hidden_count, current_hidden_dim in enumerate(hidden_dim): \n",
    "            #이전 laye의 dimension\n",
    "            for i in range(row_start, row_end + 1):\n",
    "                #print(col_start, col_end)  \n",
    "                for j in range(col_start, col_end + 1):\n",
    "\n",
    "                    hidden_wise_indices += [[i,j]]\n",
    "\n",
    "            row_start += current_hidden_dim  \n",
    "            col_start += current_hidden_dim \n",
    "            row_end += (current_hidden_dim - 1)  \n",
    "            col_end += (current_hidden_dim - 1)\n",
    "    '''\n",
    "\n",
    "    ##################################    \n",
    "    #우선 0인 element들의 indices 받아오기   \n",
    "    indices = (mat == 0)     \n",
    "    zero_indices = [] # 0이 아닌 애들 indexes 우선 받아오기 \n",
    "    for i in range(indices.shape[0]):\n",
    "        for j in range(indices.shape[1]):\n",
    "            if indices[i,j] == True:\n",
    "                zero_indices += [[i,j]]\n",
    "    \n",
    "    \n",
    "    #################################\n",
    "    # hidden_wise_indices에 해당되지 않는 zero_indices만이 possible에 포함될 수 있음  \n",
    "    # (zero_indices) and (! hidden_wise_indices)\n",
    "    # 같은 hidden layer끼리 있지 않은 인덱스들 \n",
    "    possible = zero_indices\n",
    "    #possible = [value for value in zero_indices if value not in hidden_wise_indices]  \n",
    "    \n",
    "    \n",
    "    # 우선 랜덤하게 어떤 element 바꿀 지 선택\n",
    "    ran_idx = random.choice(possible)\n",
    "    # select random activation -> 안하고 바로 liear 로 세팅\n",
    "    #possible_activation = [1, 2, 3] #linear, relu, sigmoid   \n",
    "    #ran_activation = random.choice(possible_activation)\n",
    "    \n",
    "    mat[ran_idx[0], ran_idx[1]] = 1   \n",
    "    \n",
    "    new_SparseMatrix = graphtorch.SparseMatrix(mat, in_dim, out_dim)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    return new_SparseMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add node\n",
    "- extra 4 functions need to add node except super add_node function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function 1 to add node\n",
    "def which_layer(total_dim, from_node_num, to_node_num):\n",
    "    #선택된 index가 어느 layer와 어느 layer에 해당하는지 list return \n",
    "    layer_idx = [0]*len(total_dim)\n",
    "    \n",
    "    #아래 for문으로 짜야할듯 \n",
    "    for idx in range(len(total_dim)):\n",
    "        if from_node_num <= sum(total_dim[0:(idx+1)]):  \n",
    "            layer_idx[idx] = 1\n",
    "            break\n",
    "            \n",
    "    for idx in range(len(total_dim)):  \n",
    "        if to_node_num <= sum(total_dim[0:(idx+1)]):\n",
    "            layer_idx[idx] = 1\n",
    "            break \n",
    "    \n",
    "    return layer_idx # [1,0,1,0,0] 형태로 return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function 2 to add node \n",
    "def extra_hidden_idx(layer_idx, total_dim):\n",
    "    idx_total = None\n",
    "    from_layer_idx = None\n",
    "    to_layer_idx = None\n",
    "    \n",
    "    for i in range(len(layer_idx)):\n",
    "        if from_layer_idx == None and layer_idx[i] == 1:\n",
    "            from_layer_idx = i\n",
    "        elif from_layer_idx != None and layer_idx[i] == 1:\n",
    "            to_layer_idx = i\n",
    "    print(\"from_layer_idx:{}\".format(from_layer_idx))\n",
    "    print(\"to_layer_idx:{}\".format(to_layer_idx))\n",
    "    \n",
    "    idx_total = sum(total_dim[0:(to_layer_idx)]) #이건 number은 아니고 0부터 시작하는 index \n",
    "    #num_total = idx_total + 1 #이건 앞에서부터의 순 노드 number(1부터 시작하는)\n",
    "    idx_hidden = idx_total - in_dim\n",
    "    #num_hidden = idx_hidden + 1\n",
    "    print(\"idx_total:{}\".format(idx_total))\n",
    "    #print(\"num_total:{}\".format(num_total))\n",
    "    print(\"idx_hidden:{}\".format(idx_hidden))\n",
    "    #print(\"num_hidden:{}\".format(num_hidden))\n",
    "    \n",
    "        \n",
    "    return idx_hidden # 몇 번째 hidden node에 삽입될 것인가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuction 3 to add node \n",
    "def expand_dim_mat(mat, idx_hidden, in_dim):\n",
    "    col_idx = in_dim + idx_hidden\n",
    "    row_idx = idx_hidden\n",
    "    mat = np.insert(mat, row_idx, 0, axis = 0) #index, value to fill, x axis \n",
    "    mat = np.insert(mat, col_idx, 0, axis = 1) #index, value to fill, y axis \n",
    "\n",
    "    return mat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function 4 to add node \n",
    "def change_element(mat, idx_hidden, ran_idx, in_dim, original_activation, ran_activation, front_or_back):\n",
    "    #끊기는 connection의 새로운 matrix에서의 index \n",
    "    from_idx = ran_idx[1]  \n",
    "    to_idx = ran_idx[0] + 1 #hidden에 하나 추가가 되니까 하나 뒤로 밀림 \n",
    "    #삽입된 노드의 index\n",
    "    col_idx = in_dim + idx_hidden\n",
    "    row_idx = idx_hidden\n",
    "    print(\"from_idx:{}\".format(from_idx))\n",
    "    print(\"to_idx:{}\".format(to_idx))\n",
    "    print(\"col_idx:{}\".format(col_idx))\n",
    "    print(\"row_idx:{}\".format(row_idx))\n",
    "    \n",
    "    if front_or_back == 0: #front에 새로운 activation\n",
    "        mat[row_idx, from_idx] = ran_activation\n",
    "        mat[to_idx, col_idx] = original_activation\n",
    "    elif front_or_back == 1:\n",
    "        mat[row_idx, from_idx] = original_activation\n",
    "        mat[to_idx, col_idx] = ran_activation\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node(SparseMatrix, activations):\n",
    "    \n",
    "    mat = SparseMatrix.mat \n",
    "    in_dim = SparseMatrix.in_dim\n",
    "    out_dim = SparseMatrix.out_dim  \n",
    "    hidden_dim = SparseMatrix.hidden_dim \n",
    "    \n",
    "    #이미 connection이 존재하는 부분 사이에 node 추가하기 \n",
    "    #원래 connection에 존재하던 activation 앞으로 넘길지 뒤로 넘길지 정하고, 나머지에는 랜덤하게 정해주기\n",
    "    #노드 추가해주면 dimension 추가해주고 connection 다시 계산해 줘야 하는데.. \n",
    "    \n",
    "    # connection이 존재하는 indices추출 \n",
    "    indices = (mat != 0)\n",
    "    possible = [] #node를 add할 수 있는 connection들 index 리스트 \n",
    "    for i in range(indices.shape[0]):\n",
    "        for j in range(indices.shape[1]):\n",
    "            if indices[i,j] == True:\n",
    "                possible += [[i,j]]    \n",
    "    #가능한 인덱스 중에서 하나 선택 \n",
    "    ran_idx = random.choice(possible) #[i,j] 형태로 나옴 \n",
    "    #랜덤하게 정할 activation 뽑기  \n",
    "    possible_activation = [i for i in range(len(activations))]\n",
    "    ran_activation = random.choice(possible_activation[1:]) \n",
    "    #원래 connection에 존재하던 activation type 앞으로 할지 뒤로 할지\n",
    "    front = 0 \n",
    "    back = 1\n",
    "    front_or_back = random.choice([front, back]) \n",
    "    #선택된 index의 원래 actavation 가지고있기\n",
    "    original_activation = mat[ran_idx[0], ran_idx[1]] \n",
    "    #선택된 index의 element 값 0으로 만들어주기\n",
    "    mat[ran_idx[0], ran_idx[1]] = 0\n",
    "    \n",
    "    ## 몇번째 layer에 해당하는지만   \n",
    "    #그 layer 마지막에 추가해주기   \n",
    "    total_dim = [in_dim]\n",
    "    for i in range(len(hidden_dim)):   \n",
    "        total_dim += [hidden_dim[i]]\n",
    "    total_dim += [out_dim]  \n",
    "    \n",
    "    #선택된 index 사이에 추가할 노드가 몇번째 hidden layer의 몇번째 hidden node인지 알아내야 -> mat의 index로 나오도록 \n",
    "    # 선택된 index의 from = input + 그 이전의 hidden 노드 개수 \n",
    "    # 선택된 index의 to = input + 그 이전의 hidden 노드 개수 + 그 이전의 output 노드 개수 \n",
    "    # 우선 from이 앞에서부터 몇번째 노드인지 알아내기 (1부터 시작하는 node number)  \n",
    "    from_node_num = ran_idx[1] + 1 \n",
    "    to_node_num = in_dim + ran_idx[0] + 1 \n",
    "    layer_idx = which_layer(total_dim, from_node_num, to_node_num) #function 1\n",
    "    idx_hidden = extra_hidden_idx(layer_idx, total_dim) #function 2\n",
    "    \n",
    "    #matrix dimension 늘리기(앞의 index 활용해서 늘려야함)     \n",
    "    #추가 col idx = in_dim + idx_hidden\n",
    "    #추가 row idx = idx_hidden \n",
    "    mat = expand_dim_mat(mat, idx_hidden, in_dim) #function 3\n",
    "    \n",
    "    #element 값 할당하기  \n",
    "    mat = change_element(mat, idx_hidden, ran_idx, in_dim, original_activation, ran_activation, front_or_back) #function 4  \n",
    "    \n",
    "    \n",
    "    #sparsematrix 객체 update\n",
    "    new_SparseMatrix = graphtorch.SparseMatrix(mat, in_dim, out_dim) \n",
    "    \n",
    "    return new_SparseMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat5 = np.array([[0,2,0,0,2,0,0,0,0,0],\n",
    "                [2,0,2,0,0,0,0,0,0,0],\n",
    "                [0,2,0,2,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,1,1,0,0,0],\n",
    "                [0,0,0,2,0,0,1,1,0,0],\n",
    "                [0,0,0,0,0,0,0,0,0,3],\n",
    "                [0,0,0,0,0,0,0,0,3,0]])\n",
    "in_dim = 5\n",
    "out_dim = 2\n",
    "mat_wann5 = SparseMatrix(mat5, in_dim, out_dim)\n",
    "activations = [None, None, nn.ReLU(), nn.Sigmoid()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 0 0 2 0 0 0 0 0]\n",
      " [2 0 2 0 0 0 0 0 0 0]\n",
      " [0 2 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 2 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 0 3 0]]\n"
     ]
    }
   ],
   "source": [
    "new_sparse_mat = change_activation(mat_wann5, activations)\n",
    "print(new_sparse_mat.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 0 0 2 0 0 0 0 0]\n",
      " [2 0 2 0 0 0 0 0 0 0]\n",
      " [0 2 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 2 0 0 1 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 0 3 0]]\n"
     ]
    }
   ],
   "source": [
    "new_sparse_mat = add_connection(mat_wann5)\n",
    "print(new_sparse_mat.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from_layer_idx:0\n",
      "to_layer_idx:1\n",
      "idx_total:5\n",
      "idx_hidden:0\n",
      "from_idx:3\n",
      "to_idx:3\n",
      "col_idx:5\n",
      "row_idx:0\n",
      "[[0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 2 0 0 0 0 0 0]\n",
      " [2 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 2 0 0 0 1 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 0 0 3 0]]\n"
     ]
    }
   ],
   "source": [
    "new_sparse_mat = add_node(mat_wann5, activations)\n",
    "print(new_sparse_mat.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
